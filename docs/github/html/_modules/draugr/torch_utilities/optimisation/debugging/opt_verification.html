
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>draugr.torch_utilities.optimisation.debugging.opt_verification &#8212; Draugr 1.0.0 documentation</title>
    <link rel="stylesheet" type="text/css" href="../../../../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../../../../_static/alabaster.css" />
    <link rel="stylesheet" type="text/css" href="../../../../../_static/graphviz.css" />
    <script data-url_root="../../../../../" id="documentation_options" src="../../../../../_static/documentation_options.js"></script>
    <script src="../../../../../_static/jquery.js"></script>
    <script src="../../../../../_static/underscore.js"></script>
    <script src="../../../../../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../../../../../_static/doctools.js"></script>
    <link rel="canonical" href="pything.github.io/draugr/_modules/draugr/torch_utilities/optimisation/debugging/opt_verification.html" />
    <link rel="index" title="Index" href="../../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../../search.html" />
   
  <link rel="stylesheet" href="../../../../../_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <h1>Source code for draugr.torch_utilities.optimisation.debugging.opt_verification</h1><div class="highlight"><pre>
<span></span><span class="ch">#!/usr/bin/env python3</span>
<span class="c1"># -*- coding: utf-8 -*-</span>

<span class="n">__author__</span> <span class="o">=</span> <span class="s2">&quot;Christian Heider Nielsen&quot;</span>
<span class="vm">__doc__</span> <span class="o">=</span> <span class="sa">r</span><span class="s2">&quot;&quot;&quot;</span>

<span class="s2">          Checklist items for ensuring optimisation is performed as expected.</span>


<span class="s2">verify value @ init. Verify that your value starts at the correct value value. E.g. if you initialize your final layer correctly you should measure -log(1/n_classes) on a softmax at initialization. The same default values can be derived for L2 regression, Huber losses, etc.</span>

<span class="s2">init well. Initialize the final layer weights correctly. E.g. if you are regressing some values that have a mean of 50 then initialize the final bias to 50. If you have an imbalanced dataset of a ratio 1:10 of positives:negatives, set the bias on your logits such that your network predicts probability of 0.1 at initialization. Setting these correctly will speed up convergence and eliminate “hockey stick” value curves where in the first few iteration your network is basically just learning the bias.</span>

<span class="s2">overfit one batch. Overfit a single batch of only a few examples (e.g. as little as two). To do so we increase the capacity of our model (e.g. add layers or filters) and verify that we can reach the lowest achievable value (e.g. zero). I also like to visualize in the same plot both the label and the prediction and ensure that they end up aligning perfectly once we reach the minimum value. If they do not, there is a bug somewhere and we cannot continue to the next stage.</span>

<span class="s2">verify decreasing training value. At this stage you will hopefully be underfitting on your dataset because you’re working with a toy model. Try to increase its capacity just a bit. Did your training value go down as it should?</span>

<span class="s2">visualize just before the net. The unambiguously correct place to visualize your data is immediately before your y_hat = model(x) (or sess.run in tf). That is - you want to visualize exactly what goes into your network, decoding that raw tensor of data and labels into visualizations. This is the only “source of truth”. I can’t count the number of times this has saved me and revealed problems in data preprocessing and augmentation.</span>

<span class="s2">use backprop to chart dependencies. Your deep learning code will often contain complicated, vectorized, and broadcasted operations. A relatively common bug I’ve come across a few times is that people get this wrong (e.g. they use view instead of transpose/permute somewhere) and inadvertently mix information across the batch dimension. It is a depressing fact that your network will typically still train okay because it will learn to ignore data from the other examples. One way to debug this (and other related problems) is to set the value to be something trivial like the sum of all outputs of example i, run the backward pass all the way to the input, and ensure that you get a non-zero gradient only on the i-th input. The same strategy can be used to e.g. ensure that your autoregressive model at time t only depends on 1..t-1. More generally, gradients give you information about what depends on what in your network, which can be useful for debugging.</span>

<span class="s2">#TODO: NOT DONE, FINISH!</span>

<span class="s2">           Created on 07/07/2020</span>
<span class="s2">           &quot;&quot;&quot;</span>

<span class="kn">from</span> <span class="nn">random</span> <span class="kn">import</span> <span class="n">random</span>

<span class="kn">import</span> <span class="nn">torch</span>

<span class="kn">from</span> <span class="nn">draugr.torch_utilities.tensors</span> <span class="kn">import</span> <span class="n">to_tensor</span>

<span class="n">__all__</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;overfit_single_batch&quot;</span><span class="p">]</span>


<span class="c1"># __all__ = [&#39;init_softmax_loss&#39;,&#39;overfit_single_batch&#39;]</span>


<span class="k">def</span> <span class="nf">init_softmax_loss</span><span class="p">():</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    #TODO: NOT DONE, FINISH!&quot;&quot;&quot;</span>
    <span class="n">batch_size</span> <span class="o">=</span> <span class="mi">16</span>
    <span class="n">input_f</span> <span class="o">=</span> <span class="mi">4</span>
    <span class="n">n_classes</span> <span class="o">=</span> <span class="mi">10</span>

    <span class="n">model</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">input_f</span><span class="p">,</span> <span class="mi">20</span><span class="p">),</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="n">n_classes</span><span class="p">),</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">LogSoftmax</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span>
    <span class="p">)</span>

    <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">constant_</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

    <span class="n">i</span> <span class="o">=</span> <span class="n">to_tensor</span><span class="p">([</span><span class="nb">range</span><span class="p">(</span><span class="n">input_f</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)])</span>

    <span class="nb">print</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>  <span class="c1"># Visualise input just before forward</span>
    <span class="n">out</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>

    <span class="n">target</span> <span class="o">=</span> <span class="n">to_tensor</span><span class="p">(</span>
        <span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">n_classes</span> <span class="o">*</span> <span class="n">random</span><span class="p">())</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span>
    <span class="p">)</span>
    <span class="c1"># value = torch.nn.MSELoss()(out, target)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">NLLLoss</span><span class="p">()(</span><span class="n">out</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>

    <span class="n">expected_loss</span> <span class="o">=</span> <span class="o">-</span><span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">to_tensor</span><span class="p">(</span><span class="mi">1</span> <span class="o">/</span> <span class="n">n_classes</span><span class="p">))</span>
    <span class="k">assert</span> <span class="n">expected_loss</span> <span class="o">-</span> <span class="n">loss</span> <span class="o">&lt;</span> <span class="mf">0.1</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">expected_loss</span><span class="si">}</span><span class="s2">!=</span><span class="si">{</span><span class="n">loss</span><span class="si">}</span><span class="s2">&quot;</span>


<div class="viewcode-block" id="overfit_single_batch"><a class="viewcode-back" href="../../../../../generated/draugr.torch_utilities.optimisation.debugging.opt_verification.overfit_single_batch.html#draugr.torch_utilities.optimisation.debugging.opt_verification.overfit_single_batch">[docs]</a><span class="k">def</span> <span class="nf">overfit_single_batch</span><span class="p">():</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    #TODO: NOT DONE, FINISH!</span>
<span class="sd">    :return:&quot;&quot;&quot;</span>
    <span class="n">input_f</span> <span class="o">=</span> <span class="mi">4</span>
    <span class="n">n_classes</span> <span class="o">=</span> <span class="mi">10</span>

    <span class="n">model</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">input_f</span><span class="p">,</span> <span class="mi">20</span><span class="p">),</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="n">n_classes</span><span class="p">),</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">LogSoftmax</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span>
    <span class="p">)</span>

    <span class="n">i</span> <span class="o">=</span> <span class="n">to_tensor</span><span class="p">([</span><span class="nb">range</span><span class="p">(</span><span class="n">input_f</span><span class="p">)])</span>

    <span class="nb">print</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>  <span class="c1"># Visualise input just before forward</span>
    <span class="n">out</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>

    <span class="n">target</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_classes</span><span class="p">)</span>
    <span class="n">target</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="c1"># value = torch.nn.MSELoss()(out, target)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()(</span><span class="n">out</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>

    <span class="n">expected_loss</span> <span class="o">=</span> <span class="o">-</span><span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">to_tensor</span><span class="p">(</span><span class="mi">1</span> <span class="o">/</span> <span class="n">n_classes</span><span class="p">))</span>
    <span class="k">assert</span> <span class="n">expected_loss</span> <span class="o">==</span> <span class="n">loss</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">expected_loss</span><span class="si">}</span><span class="s2">!=</span><span class="si">{</span><span class="n">loss</span><span class="si">}</span><span class="s2">&quot;</span></div>


<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">init_softmax_loss</span><span class="p">()</span>
    <span class="c1"># overfit_single_batch()</span>
</pre></div>

          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="../../../../../index.html">Draugr</a></h1>








<h3>Navigation</h3>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../../generated/draugr.html">draugr</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Notes</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../../getting_started.html">Getting Started</a></li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../../../../../index.html">Documentation overview</a><ul>
  <li><a href="../../../../index.html">Module code</a><ul>
  <li><a href="../../../../draugr.html">draugr</a><ul>
  </ul></li>
  </ul></li>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../../../../../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>document.getElementById('searchbox').style.display = "block"</script>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 5.0.2</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.12</a>
      
    </div>

    

    
  </body>
</html>