<!DOCTYPE html>

<html xmlns='http://www.w3.org/1999/xhtml'>
<head>
    <meta charset='utf-8'/>
    <title>agent.agents.ppo_agent &#8212; Agent master documentation</title>
    <link href='../../../_static/alabaster.css' rel='stylesheet' type='text/css'/>
    <link href='../../../_static/pygments.css' rel='stylesheet' type='text/css'/>
    <link href='../../../../../../../apppath/docs/github/html/_static/graphviz.css' rel='stylesheet'
          type='text/css'/>
    <script data-url_root='../../../' id='documentation_options' src='../../../_static/documentation_options.js'
            type='text/javascript'></script>
    <script src='../../../../../../../apppath/docs/github/html/_static/jquery.js'
            type='text/javascript'></script>
    <script src='../../../../../../../notus/docs/github/html/_static/underscore.js'
            type='text/javascript'></script>
    <script src='../../../../../../../apppath/docs/github/html/_static/doctools.js'
            type='text/javascript'></script>
    <script src='../../../../../../../apppath/docs/github/html/_static/language_data.js'
            type='text/javascript'></script>
    <link href='agent.neodroid.ml/_modules/agent/agents/ppo_agent.html' rel='canonical'/>
    <link href='../../../genindex.html' rel='index' title='Index'/>
    <link href='../../../../../../../apppath/docs/github/html/search.html' rel='search' title='Search'/>

    <link href='../../../_static/custom.css' rel='stylesheet' type='text/css'/>


    <meta content='width=device-width, initial-scale=0.9, maximum-scale=0.9' name='viewport'/>

</head>
<body>


<div class='document'>
    <div class='documentwrapper'>
        <div class='bodywrapper'>


            <div class='body' role='main'>

                <h1>Source code for agent.agents.ppo_agent</h1>
                <div class='highlight'><pre>
<span></span><span class='ch'>#!/usr/local/bin/python</span>
<span class='c1'># coding: utf-8</span>
<span class='kn'>from</span> <span class='nn'>itertools</span> <span class='k'>import</span> <span
                        class='n'>count</span>
<span class='kn'>from</span> <span class='nn'>typing</span> <span class='k'>import</span> <span
                        class='n'>Any</span><span class='p'>,</span> <span class='n'>Tuple</span>

<span class='kn'>import</span> <span class='nn'>numpy</span>

<span class='kn'>from</span> <span class='nn'>agent.architectures</span> <span class='k'>import</span> <span
                        class='n'>DDPGActorArchitecture</span><span class='p'>,</span> <span class='n'>DDPGCriticArchitecture</span>
<span class='kn'>from</span> <span
                        class='nn'>agent.interfaces.partials.agents.torch_agents.actor_critic_agent</span> <span
                        class='k'>import</span> <span class='n'>ActorCriticAgent</span>
<span class='kn'>from</span> <span class='nn'>agent.interfaces.specifications</span> <span
                        class='k'>import</span> <span class='n'>ValuedTransition</span>
<span class='kn'>from</span> <span class='nn'>agent.interfaces.specifications.generalised_delayed_construction_specification</span> <span
                        class='k'>import</span> <span class='n'>GDCS</span>
<span class='kn'>from</span> <span class='nn'>agent.training.procedures</span> <span
                        class='k'>import</span> <span class='n'>batched_training</span>
<span class='kn'>from</span> <span class='nn'>agent.training.train_agent</span> <span class='k'>import</span> <span
                        class='n'>parallelised_training</span><span class='p'>,</span> <span
                        class='n'>train_agent</span>
<span class='kn'>from</span> <span class='nn'>agent.utilities</span> <span class='k'>import</span> <span
                        class='n'>to_tensor</span>
<span class='kn'>from</span> <span class='nn'>warg.named_ordered_dictionary</span> <span
                        class='k'>import</span> <span class='n'>NOD</span>

<span class='n'>__author__</span> <span class='o'>=</span> <span class='s1'>&#39;cnheider&#39;</span>

<span class='kn'>import</span> <span class='nn'>torch</span>
<span class='kn'>from</span> <span class='nn'>torch</span> <span class='k'>import</span> <span
                        class='n'>nn</span>
<span class='kn'>from</span> <span class='nn'>tqdm</span> <span class='k'>import</span> <span
                        class='n'>tqdm</span>
<span class='kn'>import</span> <span class='nn'>torch.nn.functional</span> <span class='k'>as</span> <span
                        class='nn'>F</span>

<span class='kn'>from</span> <span class='nn'>agent</span> <span class='k'>import</span> <span
                        class='n'>utilities</span> <span
                        class='k'>as</span> <span class='n'>U</span>


<div class='viewcode-block' id='PPOAgent'><a class='viewcode-back'
                                             href='../../../api/agent.agents.html#agent.agents.ppo_agent.PPOAgent'>[docs]</a><span
        class='k'>class</span> <span class='nc'>PPOAgent</span><span class='p'>(</span><span
        class='n'>ActorCriticAgent</span><span
        class='p'>):</span>
  <span class='sd'>&#39;&#39;&#39;</span>
<span class='sd'>  PPO, Proximal Policy Optimization method</span>

<span class='sd'>  See method __defaults__ for default parameters</span>
<span class='sd'>&#39;&#39;&#39;</span>

  <span class='c1'># region Private</span>

  <span class='k'>def</span> <span class='nf'>__defaults__</span><span class='p'>(</span><span
            class='bp'>self</span><span class='p'>)</span> <span class='o'>-&gt;</span> <span
            class='kc'>None</span><span
            class='p'>:</span>
    <span class='bp'>self</span><span class='o'>.</span><span class='n'>_steps</span> <span class='o'>=</span> <span
            class='mi'>10</span>

    <span class='bp'>self</span><span class='o'>.</span><span class='n'>_discount_factor</span> <span
            class='o'>=</span> <span class='mf'>0.99</span>
    <span class='bp'>self</span><span class='o'>.</span><span class='n'>_gae_tau</span> <span
            class='o'>=</span> <span class='mf'>0.95</span>
    <span class='c1'># self._reached_horizon_penalty = -10.</span>

    <span class='bp'>self</span><span class='o'>.</span><span class='n'>_actor_lr</span> <span
            class='o'>=</span> <span class='mf'>3e-4</span>
    <span class='bp'>self</span><span class='o'>.</span><span class='n'>_critic_lr</span> <span
            class='o'>=</span> <span class='mf'>3e-3</span>
    <span class='bp'>self</span><span class='o'>.</span><span class='n'>_entropy_reg_coef</span> <span
            class='o'>=</span> <span class='mf'>3e-3</span>
    <span class='bp'>self</span><span class='o'>.</span><span class='n'>_value_reg_coef</span> <span
            class='o'>=</span> <span class='mf'>5e-1</span>
    <span class='bp'>self</span><span class='o'>.</span><span class='n'>_batch_size</span> <span
            class='o'>=</span> <span class='mi'>64</span>
    <span class='bp'>self</span><span class='o'>.</span><span class='n'>_mini_batch_size</span> <span
            class='o'>=</span> <span class='mi'>10</span>
    <span class='bp'>self</span><span class='o'>.</span><span
            class='n'>_initial_observation_period</span> <span class='o'>=</span> <span class='mi'>0</span>
    <span class='bp'>self</span><span class='o'>.</span><span class='n'>_target_update_tau</span> <span
            class='o'>=</span> <span class='mf'>1.0</span>
    <span class='bp'>self</span><span class='o'>.</span><span class='n'>_update_target_interval</span> <span
            class='o'>=</span> <span class='mi'>1000</span>
    <span class='bp'>self</span><span class='o'>.</span><span class='n'>_max_grad_norm</span> <span
            class='o'>=</span> <span
            class='kc'>None</span>
    <span class='bp'>self</span><span class='o'>.</span><span class='n'>_solved_threshold</span> <span
            class='o'>=</span> <span class='o'>-</span><span class='mi'>200</span>
    <span class='bp'>self</span><span class='o'>.</span><span class='n'>_test_interval</span> <span
            class='o'>=</span> <span
            class='mi'>1000</span>
    <span class='bp'>self</span><span class='o'>.</span><span class='n'>_early_stop</span> <span
            class='o'>=</span> <span class='kc'>False</span>
    <span class='bp'>self</span><span class='o'>.</span><span class='n'>_rollouts</span> <span
            class='o'>=</span> <span class='mi'>10000</span>

    <span class='bp'>self</span><span class='o'>.</span><span class='n'>_ppo_epochs</span> <span
            class='o'>=</span> <span class='mi'>4</span>
    <span class='bp'>self</span><span class='o'>.</span><span class='n'>_current_kl_beta</span> <span
            class='o'>=</span> <span class='mf'>1.00</span>

    <span class='bp'>self</span><span class='o'>.</span><span class='n'>_state_type</span> <span
            class='o'>=</span> <span class='n'>torch</span><span class='o'>.</span><span class='n'>float</span>
    <span class='bp'>self</span><span class='o'>.</span><span class='n'>_value_type</span> <span
            class='o'>=</span> <span class='n'>torch</span><span class='o'>.</span><span class='n'>float</span>
    <span class='bp'>self</span><span class='o'>.</span><span class='n'>_action_type</span> <span
            class='o'>=</span> <span class='n'>torch</span><span class='o'>.</span><span class='n'>long</span>

    <span class='c1'># params for epsilon greedy</span>
    <span class='bp'>self</span><span class='o'>.</span><span
            class='n'>_exploration_epsilon_start</span> <span class='o'>=</span> <span class='mf'>0.99</span>
    <span class='bp'>self</span><span class='o'>.</span><span class='n'>_exploration_epsilon_end</span> <span
            class='o'>=</span> <span class='mf'>0.05</span>
    <span class='bp'>self</span><span class='o'>.</span><span
            class='n'>_exploration_epsilon_decay</span> <span class='o'>=</span> <span class='mi'>10000</span>

    <span class='bp'>self</span><span class='o'>.</span><span class='n'>_use_cuda</span> <span
            class='o'>=</span> <span class='kc'>False</span>

    <span class='bp'>self</span><span class='o'>.</span><span class='n'>_surrogate_clipping_value</span> <span
            class='o'>=</span> <span class='mf'>0.2</span>

    <span class='bp'>self</span><span class='o'>.</span><span class='n'>_optimiser_spec</span> <span
            class='o'>=</span> <span class='n'>GDCS</span><span class='p'>(</span><span class='n'>torch</span><span
            class='o'>.</span><span class='n'>optim</span><span class='o'>.</span><span class='n'>Adam</span><span
            class='p'>,</span> <span class='p'>{})</span>

    <span class='bp'>self</span><span class='o'>.</span><span class='n'>_actor_arch_spec</span> <span
            class='o'>=</span> <span class='n'>GDCS</span><span class='p'>(</span><span
            class='n'>DDPGActorArchitecture</span><span
            class='p'>,</span>
                                 <span class='n'>kwargs</span><span class='o'>=</span><span
            class='n'>NOD</span><span class='p'>({</span><span class='s1'>&#39;input_shape&#39;</span><span
            class='p'>:</span>      <span class='kc'>None</span><span class='p'>,</span>  <span class='c1'># Obtain from environment</span>
                                             <span class='s1'>&#39;hidden_layers&#39;</span><span
            class='p'>:</span>    <span class='kc'>None</span><span class='p'>,</span>
                                             <span class='s1'>&#39;output_activation&#39;</span><span
            class='p'>:</span><span class='kc'>None</span><span class='p'>,</span>
                                             <span class='s1'>&#39;output_shape&#39;</span><span
            class='p'>:</span>     <span class='kc'>None</span><span class='p'>,</span>  <span class='c1'># Obtain from environment</span>
                                             <span class='p'>}))</span>

    <span class='bp'>self</span><span class='o'>.</span><span class='n'>_critic_arch_spec</span> <span
            class='o'>=</span> <span class='n'>GDCS</span><span class='p'>(</span><span
            class='n'>DDPGCriticArchitecture</span><span
            class='p'>,</span>
                                  <span class='n'>kwargs</span><span class='o'>=</span><span
            class='n'>NOD</span><span class='p'>({</span><span class='s1'>&#39;input_shape&#39;</span><span
            class='p'>:</span>      <span class='kc'>None</span><span class='p'>,</span>  <span class='c1'># Obtain from environment</span>
                                              <span class='s1'>&#39;hidden_layers&#39;</span><span
            class='p'>:</span>    <span class='kc'>None</span><span class='p'>,</span>
                                              <span class='s1'>&#39;output_activation&#39;</span><span
            class='p'>:</span><span class='kc'>None</span><span class='p'>,</span>
                                              <span class='s1'>&#39;output_shape&#39;</span><span
            class='p'>:</span>     <span class='kc'>None</span><span class='p'>,</span>  <span class='c1'># Obtain from environment</span>
                                              <span class='p'>}))</span>

    <span class='bp'>self</span><span class='o'>.</span><span class='n'>_optimiser</span> <span
            class='o'>=</span> <span class='kc'>None</span>

    <span class='bp'>self</span><span class='o'>.</span><span class='n'>_update_early_stopping</span> <span
            class='o'>=</span> <span class='kc'>None</span>
    <span class='c1'># self._update_early_stopping = self.kl_target_stop</span>

<div class='viewcode-block' id='PPOAgent.kl_target_stop'><a class='viewcode-back'
                                                            href='../../../api/agent.agents.html#agent.agents.ppo_agent.PPOAgent.kl_target_stop'>[docs]</a>  <span
        class='k'>def</span> <span class='nf'>kl_target_stop</span><span class='p'>(</span><span
        class='bp'>self</span><span class='p'>,</span>
                     <span class='n'>old_log_probs</span><span class='p'>,</span>
                     <span class='n'>new_log_probs</span><span class='p'>,</span>
                     <span class='n'>kl_target</span><span class='o'>=</span><span class='mf'>0.03</span><span
            class='p'>,</span>
                     <span class='n'>beta_max</span><span class='o'>=</span><span class='mi'>20</span><span
            class='p'>,</span>
                     <span class='n'>beta_min</span><span class='o'>=</span><span class='mi'>1</span> <span
            class='o'>/</span> <span class='mi'>20</span><span class='p'>):</span>

    <span class='sd'>&#39;&#39;&#39;</span>
<span class='sd'>    TRPO</span>

<span class='sd'>    negloss = -tf.reduce_mean(self.advantages_ph * tf.exp(self.logp - self.prev_logp))</span>
<span class='sd'>    negloss += tf.reduce_mean(self.beta_ph * self.kl_divergence)</span>
<span class='sd'>    negloss += tf.reduce_mean(self.ksi_ph * tf.square(tf.maximum(0.0, self.kl_divergence - 2 *</span>
<span class='sd'>    self.kl_target)))</span>

<span class='sd'>    self.ksi = 10</span>

<span class='sd'>    Adaptive kl_target = 0.01</span>
<span class='sd'>    Adaptive kl_target = 0.03</span>

<span class='sd'>    :param kl_target:</span>
<span class='sd'>    :param beta_max:</span>
<span class='sd'>    :param beta_min:</span>
<span class='sd'>    :param old_log_probs:</span>
<span class='sd'>    :param new_log_probs:</span>
<span class='sd'>    :return:</span>
<span class='sd'>    &#39;&#39;&#39;</span>

    <span class='n'>kl_now</span> <span class='o'>=</span> <span class='n'>torch</span><span
            class='o'>.</span><span class='n'>distributions</span><span class='o'>.</span><span
            class='n'>kl_divergence</span><span
            class='p'>(</span><span class='n'>old_log_probs</span><span class='p'>,</span> <span
            class='n'>new_log_probs</span><span
            class='p'>)</span>
    <span class='k'>if</span> <span class='n'>kl_now</span> <span class='o'>&gt;</span> <span
            class='mi'>4</span> <span class='o'>*</span> <span class='n'>kl_target</span><span class='p'>:</span>
      <span class='k'>return</span> <span class='kc'>True</span>

    <span class='k'>if</span> <span class='n'>kl_now</span> <span class='o'>&lt;</span> <span class='n'>kl_target</span> <span
            class='o'>/</span> <span class='mf'>1.5</span><span class='p'>:</span>
      <span class='bp'>self</span><span class='o'>.</span><span class='n'>_current_kl_beta</span> <span
            class='o'>/=</span> <span class='mi'>2</span>
    <span class='k'>elif</span> <span class='n'>kl_now</span> <span class='o'>&gt;</span> <span
            class='n'>kl_target</span> <span
            class='o'>*</span> <span class='mf'>1.5</span><span class='p'>:</span>
      <span class='bp'>self</span><span class='o'>.</span><span class='n'>_current_kl_beta</span> <span
            class='o'>*=</span> <span class='mi'>2</span>
    <span class='bp'>self</span><span class='o'>.</span><span class='n'>_current_kl_beta</span> <span
            class='o'>=</span> <span class='n'>numpy</span><span class='o'>.</span><span class='n'>clip</span><span
            class='p'>(</span><span class='bp'>self</span><span class='o'>.</span><span
            class='n'>_current_kl_beta</span><span class='p'>,</span> <span class='n'>beta_min</span><span
            class='p'>,</span> <span class='n'>beta_max</span><span class='p'>)</span>
    <span class='k'>return</span> <span class='kc'>False</span></div>

  <span class='c1'># endregion</span>

  <span class='c1'># region Protected</span>

  <span class='k'>def</span> <span class='nf'>_optimise</span><span class='p'>(</span><span
            class='bp'>self</span><span class='p'>,</span> <span class='n'>cost</span><span class='p'>,</span> <span
            class='o'>**</span><span class='n'>kwargs</span><span class='p'>):</span>
    <span class='bp'>self</span><span class='o'>.</span><span class='n'>_optimiser</span><span
            class='o'>.</span><span class='n'>zero_grad</span><span class='p'>()</span>

    <span class='n'>cost</span><span class='o'>.</span><span class='n'>backward</span><span
            class='p'>()</span>

    <span class='k'>if</span> <span class='bp'>self</span><span class='o'>.</span><span class='n'>_max_grad_norm</span> <span
            class='ow'>is</span> <span class='ow'>not</span> <span class='kc'>None</span><span class='p'>:</span>
      <span class='n'>nn</span><span class='o'>.</span><span class='n'>utils</span><span
            class='o'>.</span><span class='n'>clip_grad_norm</span><span class='p'>(</span><span
            class='bp'>self</span><span class='o'>.</span><span class='n'>_actor</span><span class='o'>.</span><span
            class='n'>parameters</span><span class='p'>(),</span> <span class='bp'>self</span><span
            class='o'>.</span><span class='n'>_max_grad_norm</span><span class='p'>)</span>
      <span class='n'>nn</span><span class='o'>.</span><span class='n'>utils</span><span
            class='o'>.</span><span class='n'>clip_grad_norm</span><span class='p'>(</span><span
            class='bp'>self</span><span class='o'>.</span><span class='n'>_critic</span><span
            class='o'>.</span><span class='n'>parameters</span><span class='p'>(),</span> <span
            class='bp'>self</span><span class='o'>.</span><span class='n'>_max_grad_norm</span><span
            class='p'>)</span>

    <span class='bp'>self</span><span class='o'>.</span><span class='n'>_optimiser</span><span
            class='o'>.</span><span class='n'>step</span><span class='p'>()</span>

  <span class='k'>def</span> <span class='nf'>_sample_model</span><span class='p'>(</span><span
            class='bp'>self</span><span
            class='p'>,</span> <span class='n'>state</span><span class='p'>,</span> <span class='o'>*</span><span
            class='n'>args</span><span class='p'>,</span> <span class='o'>**</span><span
            class='n'>kwargs</span><span class='p'>):</span>
    <span class='sd'>&#39;&#39;&#39;</span>
<span class='sd'>      continuous</span>
<span class='sd'>        randomly sample from normal distribution, whose mean and variance come from policy network.</span>
<span class='sd'>        [batch, action_size]</span>

<span class='sd'>      :param state:</span>
<span class='sd'>      :type state:</span>
<span class='sd'>      :param continuous:</span>
<span class='sd'>      :type continuous:</span>
<span class='sd'>      :param kwargs:</span>
<span class='sd'>      :type kwargs:</span>
<span class='sd'>      :return:</span>
<span class='sd'>      :rtype:</span>
<span class='sd'>    &#39;&#39;&#39;</span>

    <span class='n'>model_input</span> <span class='o'>=</span> <span class='n'>U</span><span
            class='o'>.</span><span class='n'>to_tensor</span><span class='p'>(</span><span
            class='n'>state</span><span class='p'>,</span> <span class='n'>device</span><span
            class='o'>=</span><span class='bp'>self</span><span class='o'>.</span><span
            class='n'>_device</span><span class='p'>,</span> <span class='n'>dtype</span><span
            class='o'>=</span><span class='bp'>self</span><span class='o'>.</span><span
            class='n'>_state_type</span><span
            class='p'>)</span>

    <span class='n'>mean</span><span class='p'>,</span> <span class='n'>std</span> <span
            class='o'>=</span> <span class='bp'>self</span><span class='o'>.</span><span
            class='n'>_actor</span><span class='p'>(</span><span class='n'>model_input</span><span
            class='p'>)</span>
    <span class='n'>value_estimate</span> <span class='o'>=</span> <span class='bp'>self</span><span
            class='o'>.</span><span class='n'>_critic</span><span class='p'>(</span><span
            class='n'>model_input</span><span class='p'>)</span>

    <span class='n'>distribution</span> <span class='o'>=</span> <span class='n'>torch</span><span
            class='o'>.</span><span class='n'>distributions</span><span class='o'>.</span><span
            class='n'>Normal</span><span class='p'>(</span><span class='n'>mean</span><span class='p'>,</span> <span
            class='n'>std</span><span class='p'>)</span>

    <span class='k'>with</span> <span class='n'>torch</span><span class='o'>.</span><span
            class='n'>no_grad</span><span class='p'>():</span>
      <span class='n'>action</span> <span class='o'>=</span> <span class='n'>distribution</span><span
            class='o'>.</span><span class='n'>sample</span><span class='p'>()</span>

    <span class='n'>action_log_prob</span> <span class='o'>=</span> <span class='n'>distribution</span><span
            class='o'>.</span><span class='n'>log_prob</span><span class='p'>(</span><span
            class='n'>action</span><span class='p'>)</span>

    <span class='k'>return</span> <span class='n'>action</span><span class='o'>.</span><span
            class='n'>detach</span><span class='p'>()</span><span class='o'>.</span><span class='n'>to</span><span
            class='p'>(</span><span class='s1'>&#39;cpu&#39;</span><span class='p'>)</span><span
            class='o'>.</span><span class='n'>numpy</span><span class='p'>(),</span> <span
            class='n'>action_log_prob</span><span class='p'>,</span> <span class='n'>value_estimate</span><span
            class='p'>,</span> <span class='n'>distribution</span>

  <span class='c1'># endregion</span>

  <span class='c1'># region Public</span>

<div class='viewcode-block' id='PPOAgent.take_n_steps'><a class='viewcode-back'
                                                          href='../../../api/agent.agents.html#agent.agents.ppo_agent.PPOAgent.take_n_steps'>[docs]</a>  <span
        class='k'>def</span> <span class='nf'>take_n_steps</span><span class='p'>(</span><span
        class='bp'>self</span><span class='p'>,</span>
                   <span class='n'>initial_state</span><span class='p'>,</span>
                   <span class='n'>environment</span><span class='p'>,</span>
                   <span class='n'>n</span><span class='o'>=</span><span class='mi'>100</span><span class='p'>,</span>
                   <span class='n'>render</span><span class='o'>=</span><span class='kc'>False</span><span
            class='p'>,</span>
                   <span class='n'>render_frequency</span><span class='o'>=</span><span
            class='mi'>100</span><span class='p'>):</span>
    <span class='n'>state</span> <span class='o'>=</span> <span class='n'>initial_state</span>

    <span class='n'>accumulated_signal</span> <span class='o'>=</span> <span class='mi'>0</span>

    <span class='n'>transitions</span> <span class='o'>=</span> <span class='p'>[]</span>
    <span class='n'>terminated</span> <span class='o'>=</span> <span class='kc'>False</span>
    <span class='n'>T</span> <span class='o'>=</span> <span class='n'>tqdm</span><span class='p'>(</span><span
            class='nb'>range</span><span class='p'>(</span><span class='mi'>1</span><span class='p'>,</span> <span
            class='n'>n</span> <span class='o'>+</span> <span class='mi'>1</span><span class='p'>),</span> <span
            class='n'>f</span><span class='s1'>&#39;Step #</span><span class='si'>{self._step_i}</span><span
            class='s1'> - </span><span class='si'>{0}</span><span class='s1'>/</span><span
            class='si'>{n}</span><span class='s1'>&#39;</span><span class='p'>,</span> <span
            class='n'>leave</span><span class='o'>=</span><span class='kc'>False</span><span
            class='p'>,</span> <span class='n'>disable</span><span class='o'>=</span><span
            class='ow'>not</span> <span class='n'>render</span><span class='p'>)</span>
    <span class='k'>for</span> <span class='n'>t</span> <span class='ow'>in</span> <span
            class='n'>T</span><span class='p'>:</span>
      <span class='c1'># T.set_description(f&#39;Step #{self._step_i} - {t}/{n}&#39;)</span>
      <span class='bp'>self</span><span class='o'>.</span><span class='n'>_step_i</span> <span
            class='o'>+=</span> <span class='mi'>1</span>
      <span class='n'>dist</span><span class='p'>,</span> <span class='n'>value_estimates</span><span
            class='p'>,</span> <span class='o'>*</span><span class='n'>_</span> <span class='o'>=</span> <span
            class='bp'>self</span><span class='o'>.</span><span class='n'>sample_action</span><span
            class='p'>(</span><span class='n'>state</span><span class='p'>)</span>

      <span class='n'>action</span> <span class='o'>=</span> <span class='n'>dist</span><span
            class='o'>.</span><span class='n'>_sample</span><span class='p'>()</span>
      <span class='n'>action_prob</span> <span class='o'>=</span> <span class='n'>dist</span><span
            class='o'>.</span><span class='n'>log_prob</span><span class='p'>(</span><span
            class='n'>action</span><span class='p'>)</span>

      <span class='n'>next_state</span><span class='p'>,</span> <span class='n'>signal</span><span
            class='p'>,</span> <span class='n'>terminated</span><span class='p'>,</span> <span
            class='n'>_</span> <span class='o'>=</span> <span class='n'>environment</span><span
            class='o'>.</span><span class='n'>react</span><span class='p'>(</span><span class='n'>action</span><span
            class='p'>)</span>

      <span class='k'>if</span> <span class='n'>render</span> <span class='ow'>and</span> <span
            class='bp'>self</span><span
            class='o'>.</span><span class='n'>_rollout_i</span> <span class='o'>%</span> <span class='n'>render_frequency</span> <span
            class='o'>==</span> <span class='mi'>0</span><span class='p'>:</span>
        <span class='n'>environment</span><span class='o'>.</span><span class='n'>render</span><span
            class='p'>()</span>

      <span class='n'>successor_state</span> <span class='o'>=</span> <span class='kc'>None</span>
      <span class='k'>if</span> <span class='ow'>not</span> <span class='n'>terminated</span><span
            class='p'>:</span>  <span class='c1'># If environment terminated then there is no successor state</span>
        <span class='n'>successor_state</span> <span class='o'>=</span> <span class='n'>next_state</span>

      <span class='n'>transitions</span><span class='o'>.</span><span class='n'>append</span><span
            class='p'>(</span>
          <span class='n'>ValuedTransition</span><span class='p'>(</span><span class='n'>state</span><span
            class='p'>,</span>
                           <span class='n'>action</span><span class='p'>,</span>
                           <span class='n'>action_prob</span><span class='p'>,</span>
                           <span class='n'>value_estimates</span><span class='p'>,</span>
                           <span class='n'>signal</span><span class='p'>,</span>
                           <span class='n'>successor_state</span><span class='p'>,</span>
                           <span class='ow'>not</span> <span class='n'>terminated</span><span
            class='p'>,</span>
                           <span class='p'>)</span>
          <span class='p'>)</span>

      <span class='n'>state</span> <span class='o'>=</span> <span class='n'>next_state</span>

      <span class='n'>accumulated_signal</span> <span class='o'>+=</span> <span class='n'>signal</span>

      <span class='k'>if</span> <span class='n'>terminated</span><span class='p'>:</span>
        <span class='n'>state</span> <span class='o'>=</span> <span class='n'>environment</span><span
            class='o'>.</span><span class='n'>reset</span><span class='p'>()</span>
        <span class='bp'>self</span><span class='o'>.</span><span class='n'>_rollout_i</span> <span class='o'>+=</span> <span
            class='mi'>1</span>

    <span class='k'>return</span> <span class='n'>transitions</span><span class='p'>,</span> <span class='n'>accumulated_signal</span><span
            class='p'>,</span> <span class='n'>terminated</span><span class='p'>,</span> <span
            class='n'>state</span></div>

<div class='viewcode-block' id='PPOAgent.react'><a class='viewcode-back'
                                                   href='../../../api/agent.agents.html#agent.agents.ppo_agent.PPOAgent.react'>[docs]</a>  <span
        class='k'>def</span> <span class='nf'>react</span><span class='p'>(</span><span
        class='bp'>self</span><span class='p'>):</span>
    <span class='k'>pass</span></div>



<div class='viewcode-block' id='PPOAgent.back_trace_advantages'><a class='viewcode-back'
                                                                   href='../../../api/agent.agents.html#agent.agents.ppo_agent.PPOAgent.back_trace_advantages'>[docs]</a>  <span
        class='k'>def</span> <span class='nf'>back_trace_advantages</span><span class='p'>(</span><span
        class='bp'>self</span><span class='p'>,</span> <span class='n'>transitions</span><span class='p'>):</span>
    <span class='n'>n_step_summary</span> <span class='o'>=</span> <span
            class='n'>ValuedTransition</span><span class='p'>(</span><span class='o'>*</span><span
            class='nb'>zip</span><span class='p'>(</span><span class='o'>*</span><span
            class='n'>transitions</span><span class='p'>))</span>

    <span class='n'>advantages</span> <span class='o'>=</span> <span class='n'>U</span><span
            class='o'>.</span><span class='n'>advantage_estimate</span><span class='p'>(</span><span class='n'>n_step_summary</span><span
            class='o'>.</span><span class='n'>signal</span><span class='p'>,</span>
                                      <span class='n'>n_step_summary</span><span class='o'>.</span><span
            class='n'>non_terminal</span><span class='p'>,</span>
                                      <span class='n'>n_step_summary</span><span class='o'>.</span><span
            class='n'>value_estimate</span><span class='p'>,</span>
                                      <span class='n'>discount_factor</span><span class='o'>=</span><span
            class='bp'>self</span><span class='o'>.</span><span class='n'>_discount_factor</span><span
            class='p'>,</span>
                                      <span class='n'>tau</span><span class='o'>=</span><span
            class='bp'>self</span><span class='o'>.</span><span class='n'>_gae_tau</span><span class='p'>,</span>
                                      <span class='n'>device</span><span class='o'>=</span><span
            class='bp'>self</span><span
            class='o'>.</span><span class='n'>_device</span>
                                      <span class='p'>)</span>

    <span class='n'>value_estimates</span> <span class='o'>=</span> <span class='n'>U</span><span
            class='o'>.</span><span class='n'>to_tensor</span><span class='p'>(</span><span
            class='n'>n_step_summary</span><span class='o'>.</span><span class='n'>value_estimate</span><span
            class='p'>,</span> <span class='n'>device</span><span class='o'>=</span><span
            class='bp'>self</span><span class='o'>.</span><span class='n'>_device</span><span class='p'>)</span>

    <span class='n'>discounted_returns</span> <span class='o'>=</span> <span class='n'>value_estimates</span> <span
            class='o'>+</span> <span class='n'>advantages</span>

    <span class='n'>i</span> <span class='o'>=</span> <span class='mi'>0</span>
    <span class='n'>advantage_memories</span> <span class='o'>=</span> <span class='p'>[]</span>
    <span class='k'>for</span> <span class='n'>step</span> <span class='ow'>in</span> <span
            class='nb'>zip</span><span class='p'>(</span><span class='o'>*</span><span
            class='n'>n_step_summary</span><span class='p'>):</span>
      <span class='n'>step</span> <span class='o'>=</span> <span class='n'>ValuedTransition</span><span
            class='p'>(</span><span class='o'>*</span><span class='n'>step</span><span class='p'>)</span>
      <span class='n'>advantage_memories</span><span class='o'>.</span><span class='n'>append</span><span
            class='p'>(</span>
          <span class='n'>ValuedTransition</span><span class='p'>(</span>
              <span class='n'>step</span><span class='o'>.</span><span class='n'>state</span><span
            class='p'>,</span>
              <span class='n'>step</span><span class='o'>.</span><span class='n'>action</span><span class='p'>,</span>
              <span class='n'>discounted_returns</span><span class='p'>[</span><span class='n'>i</span><span
            class='p'>],</span>
              <span class='n'>step</span><span class='o'>.</span><span class='n'>successor_state</span><span
            class='p'>,</span>
              <span class='n'>step</span><span class='o'>.</span><span class='n'>terminal</span><span
            class='p'>,</span>
              <span class='n'>step</span><span class='o'>.</span><span class='n'>action_prob</span><span
            class='p'>,</span>
              <span class='n'>advantages</span><span class='p'>[</span><span class='n'>i</span><span
            class='p'>]</span>
              <span class='p'>)</span>
          <span class='p'>)</span>
      <span class='n'>i</span> <span class='o'>+=</span> <span class='mi'>1</span>

    <span class='k'>return</span> <span class='n'>advantage_memories</span></div>

<div class='viewcode-block' id='PPOAgent.evaluate3'><a class='viewcode-back'
                                                       href='../../../api/agent.agents.html#agent.agents.ppo_agent.PPOAgent.evaluate3'>[docs]</a>  <span
        class='k'>def</span> <span class='nf'>evaluate3</span><span class='p'>(</span><span class='bp'>self</span><span
        class='p'>,</span> <span class='n'>batch</span><span class='p'>,</span> <span
        class='n'>discrete</span><span class='o'>=</span><span class='kc'>False</span><span
        class='p'>,</span> <span class='o'>**</span><span class='n'>kwargs</span><span class='p'>):</span>
    <span class='c1'># region Tensorise</span>

    <span class='n'>states</span> <span class='o'>=</span> <span class='n'>U</span><span
            class='o'>.</span><span class='n'>to_tensor</span><span class='p'>(</span><span
            class='n'>batch</span><span class='o'>.</span><span class='n'>state</span><span class='p'>,</span> <span
            class='n'>device</span><span class='o'>=</span><span class='bp'>self</span><span class='o'>.</span><span
            class='n'>_device</span><span class='p'>)</span><span class='o'>.</span><span class='n'>view</span><span
            class='p'>(</span><span class='o'>-</span><span class='mi'>1</span><span class='p'>,</span> <span
            class='bp'>self</span><span class='o'>.</span><span class='n'>_input_shape</span><span
            class='p'>[</span><span class='mi'>0</span><span class='p'>])</span>

    <span class='n'>value_estimates</span> <span class='o'>=</span> <span class='n'>U</span><span
            class='o'>.</span><span class='n'>to_tensor</span><span class='p'>(</span><span
            class='n'>batch</span><span class='o'>.</span><span class='n'>value_estimate</span><span
            class='p'>,</span> <span class='n'>device</span><span class='o'>=</span><span
            class='bp'>self</span><span class='o'>.</span><span class='n'>_device</span><span class='p'>)</span>

    <span class='n'>advantages</span> <span class='o'>=</span> <span class='n'>U</span><span
            class='o'>.</span><span class='n'>to_tensor</span><span class='p'>(</span><span
            class='n'>batch</span><span class='o'>.</span><span class='n'>advantage</span><span
            class='p'>,</span> <span class='n'>device</span><span class='o'>=</span><span
            class='bp'>self</span><span class='o'>.</span><span class='n'>_device</span><span class='p'>)</span>

    <span class='n'>discounted_returns</span> <span class='o'>=</span> <span class='n'>U</span><span
            class='o'>.</span><span class='n'>to_tensor</span><span class='p'>(</span><span
            class='n'>batch</span><span class='o'>.</span><span class='n'>discounted_return</span><span
            class='p'>,</span> <span class='n'>device</span><span class='o'>=</span><span
            class='bp'>self</span><span class='o'>.</span><span class='n'>_device</span><span class='p'>)</span>

    <span class='n'>action_probs_old</span> <span class='o'>=</span> <span class='n'>U</span><span
            class='o'>.</span><span class='n'>to_tensor</span><span class='p'>(</span><span
            class='n'>batch</span><span class='o'>.</span><span class='n'>action_prob</span><span
            class='p'>,</span> <span
            class='n'>device</span><span class='o'>=</span><span class='bp'>self</span><span class='o'>.</span><span
            class='n'>_device</span><span class='p'>)</span><span class='o'>.</span><span class='n'>view</span><span
            class='p'>(</span><span class='o'>-</span><span class='mi'>1</span><span class='p'>,</span> <span
            class='bp'>self</span><span class='o'>.</span><span class='n'>_output_shape</span><span
            class='p'>[</span><span class='mi'>0</span><span class='p'>])</span>

    <span class='c1'># endregion</span>

    <span class='n'>advantage</span> <span class='o'>=</span> <span class='p'>(</span><span class='n'>advantages</span> <span
            class='o'>-</span> <span class='n'>advantages</span><span class='o'>.</span><span
            class='n'>mean</span><span class='p'>())</span> <span class='o'>/</span> <span class='p'>(</span><span
            class='n'>advantages</span><span class='o'>.</span><span class='n'>std</span><span
            class='p'>()</span> <span class='o'>+</span> <span class='bp'>self</span><span class='o'>.</span><span
            class='n'>_divide_by_zero_safety</span><span class='p'>)</span>

    <span class='o'>*</span><span class='n'>_</span><span class='p'>,</span> <span
            class='n'>action_probs_new</span><span class='p'>,</span> <span class='n'>distribution</span> <span
            class='o'>=</span> <span class='bp'>self</span><span class='o'>.</span><span
            class='n'>_sample_model</span><span class='p'>(</span><span class='n'>states</span><span
            class='p'>)</span>

    <span class='k'>if</span> <span class='n'>discrete</span><span class='p'>:</span>
      <span class='n'>actions</span> <span class='o'>=</span> <span class='n'>U</span><span class='o'>.</span><span
            class='n'>to_tensor</span><span class='p'>(</span><span class='n'>batch</span><span
            class='o'>.</span><span class='n'>action</span><span class='p'>,</span> <span
            class='n'>device</span><span class='o'>=</span><span class='bp'>self</span><span class='o'>.</span><span
            class='n'>_device</span><span class='p'>)</span><span class='o'>.</span><span class='n'>view</span><span
            class='p'>(</span><span class='o'>-</span><span class='mi'>1</span><span class='p'>,</span> <span
            class='bp'>self</span><span class='o'>.</span><span class='n'>_output_shape</span><span
            class='p'>[</span><span class='mi'>0</span><span class='p'>])</span>
      <span class='n'>action_probs_old</span> <span class='o'>=</span> <span class='n'>action_probs_old</span><span
            class='o'>.</span><span class='n'>gather</span><span class='p'>(</span><span class='mi'>1</span><span
            class='p'>,</span> <span class='n'>actions</span><span class='p'>)</span>
      <span class='n'>action_probs_new</span> <span class='o'>=</span> <span class='n'>action_probs_new</span><span
            class='o'>.</span><span class='n'>gather</span><span class='p'>(</span><span class='mi'>1</span><span
            class='p'>,</span> <span class='n'>actions</span><span class='p'>)</span>

    <span class='n'>ratio</span> <span class='o'>=</span> <span class='p'>(</span><span
            class='n'>action_probs_new</span> <span
            class='o'>-</span> <span class='n'>action_probs_old</span><span class='p'>)</span><span
            class='o'>.</span><span class='n'>exp</span><span class='p'>()</span>
    <span class='c1'># Generated action probs from (new policy) and (old policy).</span>
    <span class='c1'># Values of [0..1] means that actions less likely with the new policy,</span>
    <span class='c1'># while values [&gt;1] mean action a more likely now</span>

    <span class='n'>surrogate</span> <span class='o'>=</span> <span class='n'>ratio</span> <span
            class='o'>*</span> <span class='n'>advantage</span>

    <span class='n'>clamped_ratio</span> <span class='o'>=</span> <span class='n'>torch</span><span
            class='o'>.</span><span
            class='n'>clamp</span><span class='p'>(</span><span class='n'>ratio</span><span class='p'>,</span>
                                <span class='nb'>min</span><span class='o'>=</span><span class='mf'>1.</span> <span
            class='o'>-</span> <span class='bp'>self</span><span class='o'>.</span><span class='n'>_surrogate_clipping_value</span><span
            class='p'>,</span>
                                <span class='nb'>max</span><span class='o'>=</span><span class='mf'>1.</span> <span
            class='o'>+</span> <span class='bp'>self</span><span class='o'>.</span><span class='n'>_surrogate_clipping_value</span><span
            class='p'>)</span>
    <span class='n'>surrogate_clipped</span> <span class='o'>=</span> <span
            class='n'>clamped_ratio</span> <span class='o'>*</span> <span class='n'>advantage</span>  <span
            class='c1'># (L^CLIP)</span>

    <span class='n'>policy_loss</span> <span class='o'>=</span> <span class='o'>-</span><span
            class='n'>torch</span><span class='o'>.</span><span class='n'>min</span><span class='p'>(</span><span
            class='n'>surrogate</span><span class='p'>,</span> <span class='n'>surrogate_clipped</span><span
            class='p'>)</span><span class='o'>.</span><span class='n'>mean</span><span class='p'>()</span>

    <span class='n'>entropy_loss</span> <span class='o'>=</span> <span class='n'>distribution</span><span
            class='o'>.</span><span class='n'>entropy</span><span class='p'>()</span><span class='o'>.</span><span
            class='n'>mean</span><span class='p'>()</span>

    <span class='c1'># value_error = (value_estimates - discounted_returns).pow(2).mean()</span>
    <span class='n'>value_error</span> <span class='o'>=</span> <span class='n'>F</span><span
            class='o'>.</span><span class='n'>mse_loss</span><span class='p'>(</span><span
            class='n'>value_estimates</span><span class='p'>,</span> <span class='n'>discounted_returns</span><span
            class='p'>)</span>

    <span class='n'>collective_cost</span> <span class='o'>=</span> <span class='n'>policy_loss</span> <span
            class='o'>+</span> <span class='n'>value_error</span> <span class='o'>*</span> <span
            class='bp'>self</span><span class='o'>.</span><span class='n'>_value_reg_coef</span> <span
            class='o'>-</span> <span class='n'>entropy_loss</span> <span class='o'>*</span> <span
            class='bp'>self</span><span class='o'>.</span><span class='n'>_entropy_reg_coef</span>

    <span class='k'>return</span> <span class='n'>collective_cost</span><span class='p'>,</span> <span
            class='n'>policy_loss</span><span class='p'>,</span> <span class='n'>value_error</span></div>

<div class='viewcode-block' id='PPOAgent.evaluate2'><a class='viewcode-back'
                                                       href='../../../api/agent.agents.html#agent.agents.ppo_agent.PPOAgent.evaluate2'>[docs]</a>  <span
        class='k'>def</span> <span class='nf'>evaluate2</span><span class='p'>(</span><span class='bp'>self</span><span
        class='p'>,</span>
                <span class='o'>*</span><span class='p'>,</span>
                <span class='n'>states</span><span class='p'>,</span>
                <span class='n'>actions</span><span class='p'>,</span>
                <span class='n'>log_probs</span><span class='p'>,</span>
                <span class='n'>returns</span><span class='p'>,</span>
                <span class='n'>advantage</span><span class='p'>,</span>
                <span class='o'>**</span><span class='n'>kwargs</span><span class='p'>):</span>
    <span class='n'>action_out</span><span class='p'>,</span> <span class='n'>action_log_prob</span><span
            class='p'>,</span> <span class='n'>value_estimate</span><span class='p'>,</span> <span class='n'>distribution</span> <span
            class='o'>=</span> <span class='bp'>self</span><span class='o'>.</span><span
            class='n'>_sample_model</span><span class='p'>(</span><span class='n'>states</span><span
            class='p'>)</span>

    <span class='n'>old_log_probs</span> <span class='o'>=</span> <span class='n'>log_probs</span>
    <span class='n'>new_log_probs</span> <span class='o'>=</span> <span class='n'>distribution</span><span
            class='o'>.</span><span class='n'>log_prob</span><span class='p'>(</span><span
            class='n'>actions</span><span class='p'>)</span>

    <span class='n'>ratio</span> <span class='o'>=</span> <span class='p'>(</span><span
            class='n'>new_log_probs</span> <span
            class='o'>-</span> <span class='n'>old_log_probs</span><span class='p'>)</span><span
            class='o'>.</span><span class='n'>exp</span><span class='p'>()</span>
    <span class='n'>surrogate</span> <span class='o'>=</span> <span class='n'>ratio</span> <span
            class='o'>*</span> <span class='n'>advantage</span>
    <span class='n'>surrogate_clipped</span> <span class='o'>=</span> <span class='p'>(</span><span
            class='n'>torch</span><span
            class='o'>.</span><span class='n'>clamp</span><span class='p'>(</span><span class='n'>ratio</span><span
            class='p'>,</span>
                                     <span class='mf'>1.0</span> <span class='o'>-</span> <span
            class='bp'>self</span><span
            class='o'>.</span><span class='n'>_surrogate_clipping_value</span><span class='p'>,</span>
                                     <span class='mf'>1.0</span> <span class='o'>+</span> <span
            class='bp'>self</span><span
            class='o'>.</span><span class='n'>_surrogate_clipping_value</span><span class='p'>)</span>
                         <span class='o'>*</span> <span class='n'>advantage</span><span class='p'>)</span>

    <span class='n'>actor_loss</span> <span class='o'>=</span> <span class='o'>-</span> <span
            class='n'>torch</span><span class='o'>.</span><span class='n'>min</span><span class='p'>(</span><span
            class='n'>surrogate</span><span class='p'>,</span> <span class='n'>surrogate_clipped</span><span
            class='p'>)</span><span class='o'>.</span><span class='n'>mean</span><span class='p'>()</span>
    <span class='c1'># critic_loss = (value_estimate-returns).pow(2).mean()</span>
    <span class='n'>critic_loss</span> <span class='o'>=</span> <span class='n'>F</span><span
            class='o'>.</span><span class='n'>mse_loss</span><span class='p'>(</span><span
            class='n'>value_estimate</span><span class='p'>,</span> <span class='n'>returns</span><span
            class='p'>)</span>

    <span class='n'>entropy</span> <span class='o'>=</span> <span class='n'>distribution</span><span
            class='o'>.</span><span class='n'>entropy</span><span class='p'>()</span><span class='o'>.</span><span
            class='n'>mean</span><span class='p'>()</span>

    <span class='n'>loss</span> <span class='o'>=</span> <span class='bp'>self</span><span
            class='o'>.</span><span class='n'>_value_reg_coef</span> <span class='o'>*</span> <span class='n'>critic_loss</span> <span
            class='o'>+</span> <span class='n'>actor_loss</span> <span class='o'>-</span> <span
            class='n'>entropy</span> <span class='o'>+</span> <span class='bp'>self</span><span
            class='o'>.</span><span class='n'>_entropy_reg_coef</span>
    <span class='k'>return</span> <span class='n'>loss</span><span class='p'>,</span> <span
            class='n'>new_log_probs</span><span
            class='p'>,</span> <span class='n'>old_log_probs</span></div>

<div class='viewcode-block' id='PPOAgent.update_targets'><a class='viewcode-back'
                                                            href='../../../api/agent.agents.html#agent.agents.ppo_agent.PPOAgent.update_targets'>[docs]</a>  <span
        class='k'>def</span> <span class='nf'>update_targets</span><span class='p'>(</span><span
        class='bp'>self</span><span class='p'>,</span> <span class='o'>*</span><span class='n'>args</span><span
        class='p'>,</span> <span class='o'>**</span><span class='n'>kwargs</span><span class='p'>)</span> <span
        class='o'>-&gt;</span> <span class='kc'>None</span><span class='p'>:</span>
    <span class='bp'>self</span><span class='o'>.</span><span class='n'>update_target</span><span
            class='p'>(</span><span class='n'>target_model</span><span class='o'>=</span><span
            class='bp'>self</span><span class='o'>.</span><span class='n'>_target_actor</span><span
            class='p'>,</span>
                       <span class='n'>source_model</span><span class='o'>=</span><span class='bp'>self</span><span
            class='o'>.</span><span class='n'>_actor</span><span class='p'>,</span>
                       <span class='n'>target_update_tau</span><span class='o'>=</span><span
            class='bp'>self</span><span class='o'>.</span><span class='n'>_target_update_tau</span><span
            class='p'>)</span>
    <span class='bp'>self</span><span class='o'>.</span><span class='n'>update_target</span><span
            class='p'>(</span><span class='n'>target_model</span><span class='o'>=</span><span
            class='bp'>self</span><span class='o'>.</span><span class='n'>_target_critic</span><span
            class='p'>,</span>
                       <span class='n'>source_model</span><span class='o'>=</span><span class='bp'>self</span><span
            class='o'>.</span><span class='n'>_critic</span><span class='p'>,</span>
                       <span class='n'>target_update_tau</span><span class='o'>=</span><span
            class='bp'>self</span><span class='o'>.</span><span class='n'>_target_update_tau</span><span
            class='p'>)</span></div>

<div class='viewcode-block' id='PPOAgent.evaluate'><a class='viewcode-back'
                                                      href='../../../api/agent.agents.html#agent.agents.ppo_agent.PPOAgent.evaluate'>[docs]</a>  <span
        class='k'>def</span> <span class='nf'>evaluate</span><span class='p'>(</span><span
        class='bp'>self</span><span class='p'>,</span> <span class='n'>batch</span><span class='p'>,</span> <span
        class='n'>_last_value_estimate</span><span class='p'>,</span> <span class='n'>discrete</span><span
        class='o'>=</span><span class='kc'>False</span><span class='p'>,</span> <span class='o'>**</span><span
        class='n'>kwargs</span><span class='p'>):</span>
    <span class='n'>returns_</span> <span class='o'>=</span> <span class='n'>U</span><span
            class='o'>.</span><span class='n'>compute_gae</span><span class='p'>(</span><span class='n'>_last_value_estimate</span><span
            class='p'>,</span>
                             <span class='n'>batch</span><span class='o'>.</span><span class='n'>signal</span><span
            class='p'>,</span>
                             <span class='n'>batch</span><span class='o'>.</span><span
            class='n'>non_terminal</span><span class='p'>,</span>
                             <span class='n'>batch</span><span class='o'>.</span><span
            class='n'>value_estimate</span><span
            class='p'>,</span>
                             <span class='n'>discount_factor</span><span class='o'>=</span><span
            class='bp'>self</span><span
            class='o'>.</span><span class='n'>_discount_factor</span><span class='p'>,</span>
                             <span class='n'>tau</span><span class='o'>=</span><span
            class='bp'>self</span><span class='o'>.</span><span class='n'>_gae_tau</span><span class='p'>)</span>

    <span class='n'>returns</span> <span class='o'>=</span> <span class='n'>torch</span><span
            class='o'>.</span><span class='n'>cat</span><span class='p'>(</span><span class='n'>returns_</span><span
            class='p'>)</span><span class='o'>.</span><span class='n'>detach</span><span class='p'>()</span>
    <span class='n'>log_probs</span> <span class='o'>=</span> <span class='n'>torch</span><span
            class='o'>.</span><span class='n'>cat</span><span class='p'>(</span><span class='n'>batch</span><span
            class='o'>.</span><span class='n'>action_prob</span><span class='p'>)</span><span
            class='o'>.</span><span class='n'>detach</span><span class='p'>()</span>
    <span class='n'>values</span> <span class='o'>=</span> <span class='n'>torch</span><span
            class='o'>.</span><span class='n'>cat</span><span class='p'>(</span><span class='n'>batch</span><span
            class='o'>.</span><span class='n'>value_estimate</span><span class='p'>)</span><span
            class='o'>.</span><span class='n'>detach</span><span class='p'>()</span>
    <span class='n'>states</span> <span class='o'>=</span> <span class='n'>torch</span><span
            class='o'>.</span><span class='n'>cat</span><span class='p'>(</span><span class='n'>batch</span><span
            class='o'>.</span><span class='n'>state</span><span class='p'>)</span><span class='o'>.</span><span
            class='n'>view</span><span class='p'>(</span><span class='o'>-</span><span class='mi'>1</span><span
            class='p'>,</span> <span class='bp'>self</span><span class='o'>.</span><span
            class='n'>_input_shape</span><span class='p'>[</span><span class='mi'>0</span><span class='p'>])</span>
    <span class='n'>actions</span> <span class='o'>=</span> <span class='n'>to_tensor</span><span
            class='p'>(</span><span class='n'>batch</span><span class='o'>.</span><span class='n'>action</span><span
            class='p'>)</span><span class='o'>.</span><span class='n'>view</span><span class='p'>(</span><span
            class='o'>-</span><span class='mi'>1</span><span class='p'>,</span><span class='bp'>self</span><span
            class='o'>.</span><span class='n'>_output_shape</span><span class='p'>[</span><span
            class='mi'>0</span><span class='p'>])</span>

    <span class='n'>advantage</span> <span class='o'>=</span> <span class='n'>returns</span> <span
            class='o'>-</span> <span class='n'>values</span>

    <span class='bp'>self</span><span class='o'>.</span><span class='n'>inner_ppo_update</span><span
            class='p'>(</span><span class='n'>states</span><span class='p'>,</span>
                          <span class='n'>actions</span><span class='p'>,</span>
                          <span class='n'>log_probs</span><span class='p'>,</span>
                          <span class='n'>returns</span><span class='p'>,</span>
                          <span class='n'>advantage</span><span class='p'>)</span>

    <span class='k'>if</span> <span class='bp'>self</span><span class='o'>.</span><span
            class='n'>_step_i</span> <span class='o'>%</span> <span class='bp'>self</span><span
            class='o'>.</span><span class='n'>_update_target_interval</span> <span class='o'>==</span> <span
            class='mi'>0</span><span class='p'>:</span>
      <span class='bp'>self</span><span class='o'>.</span><span class='n'>update_targets</span><span
            class='p'>()</span>

    <span class='k'>return</span> <span class='n'>returns</span><span class='p'>,</span><span class='n'>log_probs</span><span
            class='p'>,</span><span class='n'>values</span><span class='p'>,</span><span
            class='n'>states</span><span class='p'>,</span><span class='n'>actions</span><span
            class='p'>,</span><span class='n'>advantage</span></div>

<div class='viewcode-block' id='PPOAgent.update_models'><a class='viewcode-back'
                                                           href='../../../api/agent.agents.html#agent.agents.ppo_agent.PPOAgent.update_models'>[docs]</a>  <span
        class='k'>def</span> <span class='nf'>update_models</span><span class='p'>(</span><span
        class='bp'>self</span><span class='p'>,</span> <span class='o'>*</span><span class='p'>,</span> <span
        class='n'>stat_writer</span> <span class='o'>=</span> <span class='kc'>None</span><span class='p'>,</span> <span
        class='o'>**</span><span class='n'>kwargs</span><span class='p'>)</span> <span
        class='o'>-&gt;</span> <span class='kc'>None</span><span class='p'>:</span>
    <span class='k'>pass</span>
    <span class='sd'>&#39;&#39;&#39;</span>
<span class='sd'>    batch = U.AdvantageMemory(*zip(*self._memory_buffer.sample()))</span>
<span class='sd'>    collective_cost, actor_loss, critic_loss = self.evaluate(batch)</span>

<span class='sd'>    self._optimise_wrt(collective_cost)</span>
<span class='sd'>    &#39;&#39;&#39;</span></div>

<div class='viewcode-block' id='PPOAgent.inner_ppo_update'><a class='viewcode-back'
                                                              href='../../../api/agent.agents.html#agent.agents.ppo_agent.PPOAgent.inner_ppo_update'>[docs]</a>  <span
        class='k'>def</span> <span class='nf'>inner_ppo_update</span><span class='p'>(</span><span
        class='bp'>self</span><span class='p'>,</span>
                       <span class='n'>states</span><span class='p'>,</span>
                       <span class='n'>actions</span><span class='p'>,</span>
                       <span class='n'>log_probs</span><span class='p'>,</span>
                       <span class='n'>returns</span><span class='p'>,</span>
                       <span class='n'>advantages</span><span class='p'>,</span>
                       <span class='p'>):</span>
    <span class='n'>mini_batch_gen</span> <span class='o'>=</span> <span class='bp'>self</span><span
            class='o'>.</span><span class='n'>ppo_mini_batch_iter</span><span class='p'>(</span><span
            class='bp'>self</span><span
            class='o'>.</span><span class='n'>_mini_batch_size</span><span class='p'>,</span>
                                              <span class='n'>states</span><span class='p'>,</span>
                                              <span class='n'>actions</span><span class='p'>,</span>
                                              <span class='n'>log_probs</span><span class='p'>,</span>
                                              <span class='n'>returns</span><span class='p'>,</span>
                                              <span class='n'>advantages</span><span class='p'>)</span>
    <span class='k'>for</span> <span class='n'>_</span> <span class='ow'>in</span> <span
            class='nb'>range</span><span class='p'>(</span><span class='bp'>self</span><span class='o'>.</span><span
            class='n'>_ppo_epochs</span><span class='p'>):</span>
      <span class='k'>try</span><span class='p'>:</span>
        <span class='n'>batch</span> <span class='o'>=</span> <span class='n'>mini_batch_gen</span><span
            class='o'>.</span><span class='fm'>__next__</span><span class='p'>()</span>
      <span class='k'>except</span> <span class='ne'>StopIteration</span><span class='p'>:</span>
        <span class='k'>return</span>

      <span class='n'>loss</span><span class='p'>,</span> <span class='n'>new_log_probs</span><span
            class='p'>,</span> <span
            class='n'>old_log_probs</span> <span class='o'>=</span> <span class='bp'>self</span><span
            class='o'>.</span><span class='n'>evaluate2</span><span class='p'>(</span><span class='o'>**</span><span
            class='n'>batch</span><span class='o'>.</span><span class='n'>as_dict</span><span class='p'>())</span>

      <span class='bp'>self</span><span class='o'>.</span><span class='n'>_actor_optimiser</span><span
            class='o'>.</span><span class='n'>zero_grad</span><span class='p'>()</span>
      <span class='bp'>self</span><span class='o'>.</span><span class='n'>_critic_optimiser</span><span
            class='o'>.</span><span class='n'>zero_grad</span><span class='p'>()</span>
      <span class='n'>loss</span><span class='o'>.</span><span class='n'>backward</span><span
            class='p'>()</span>
      <span class='bp'>self</span><span class='o'>.</span><span class='n'>_actor_optimiser</span><span
            class='o'>.</span><span class='n'>step</span><span class='p'>()</span>
      <span class='bp'>self</span><span class='o'>.</span><span class='n'>_critic_optimiser</span><span
            class='o'>.</span><span class='n'>step</span><span class='p'>()</span>

      <span class='k'>if</span> <span class='bp'>self</span><span class='o'>.</span><span class='n'>_update_early_stopping</span><span
            class='p'>:</span>
        <span class='k'>if</span> <span class='bp'>self</span><span class='o'>.</span><span class='n'>_update_early_stopping</span><span
            class='p'>(</span><span class='n'>old_log_probs</span><span class='p'>,</span> <span
            class='n'>new_log_probs</span><span
            class='p'>):</span>
          <span class='k'>break</span></div>





<div class='viewcode-block' id='PPOAgent.ppo_mini_batch_iter'><a class='viewcode-back'
                                                                 href='../../../api/agent.agents.html#agent.agents.ppo_agent.PPOAgent.ppo_mini_batch_iter'>[docs]</a>  <span
        class='nd'>@staticmethod</span>
  <span class='k'>def</span> <span class='nf'>ppo_mini_batch_iter</span><span class='p'>(</span><span
            class='n'>mini_batch_size</span><span class='p'>:</span> <span class='nb'>int</span><span
            class='p'>,</span>
                          <span class='n'>states</span><span class='p'>:</span> <span
            class='n'>Any</span><span class='p'>,</span>
                          <span class='n'>actions</span><span class='p'>:</span> <span
            class='n'>Any</span><span class='p'>,</span>
                          <span class='n'>log_probs</span><span class='p'>:</span> <span
            class='n'>Any</span><span class='p'>,</span>
                          <span class='n'>returns</span><span class='p'>:</span> <span
            class='n'>Any</span><span class='p'>,</span>
                          <span class='n'>advantage</span><span class='p'>:</span> <span
            class='n'>Any</span><span class='p'>)</span> <span class='o'>-&gt;</span> <span
            class='nb'>iter</span><span class='p'>:</span>

    <span class='n'>batch_size</span> <span class='o'>=</span> <span class='n'>actions</span><span
            class='o'>.</span><span class='n'>size</span><span class='p'>(</span><span class='mi'>0</span><span
            class='p'>)</span>
    <span class='k'>for</span> <span class='n'>_</span> <span class='ow'>in</span> <span
            class='nb'>range</span><span class='p'>(</span><span class='n'>batch_size</span> <span
            class='o'>//</span> <span class='n'>mini_batch_size</span><span class='p'>):</span>
      <span class='n'>rand_ids</span> <span class='o'>=</span> <span class='n'>numpy</span><span
            class='o'>.</span><span class='n'>random</span><span class='o'>.</span><span
            class='n'>randint</span><span class='p'>(</span><span class='mi'>0</span><span class='p'>,</span> <span
            class='n'>batch_size</span><span class='p'>,</span> <span class='n'>mini_batch_size</span><span
            class='p'>)</span>
      <span class='k'>yield</span> <span class='n'>NOD</span><span class='p'>(</span><span
            class='n'>states</span><span class='o'>=</span><span class='n'>states</span><span
            class='p'>[</span><span class='n'>rand_ids</span><span class='p'>,</span> <span class='p'>:],</span>
                <span class='n'>actions</span><span class='o'>=</span><span class='n'>actions</span><span
            class='p'>[</span><span class='n'>rand_ids</span><span class='p'>,</span> <span class='p'>:],</span>
                <span class='n'>log_probs</span><span class='o'>=</span><span class='n'>log_probs</span><span
            class='p'>[</span><span class='n'>rand_ids</span><span class='p'>,</span> <span class='p'>:],</span>
                <span class='n'>returns</span><span class='o'>=</span><span class='n'>returns</span><span
            class='p'>[</span><span class='n'>rand_ids</span><span class='p'>,</span> <span class='p'>:],</span>
                <span class='n'>advantage</span><span class='o'>=</span><span class='n'>advantage</span><span
            class='p'>[</span><span class='n'>rand_ids</span><span class='p'>,</span> <span
            class='p'>:])</span></div></div>

  <span class='c1'># endregion</span>


<span class='c1'># region Test</span>
<div class='viewcode-block' id='ppo_test'><a class='viewcode-back'
                                             href='../../../api/agent.agents.html#agent.agents.ppo_agent.ppo_test'>[docs]</a><span
        class='k'>def</span> <span class='nf'>ppo_test</span><span class='p'>(</span><span
        class='n'>rollouts</span><span class='o'>=</span><span class='kc'>None</span><span
        class='p'>,</span> <span class='n'>skip</span><span class='o'>=</span><span class='kc'>True</span><span
        class='p'>):</span>
  <span class='kn'>import</span> <span
            class='nn'>agent.configs.agent_test_configs.ppo_test_config</span> <span class='k'>as</span> <span
            class='nn'>C</span>

  <span class='k'>if</span> <span class='n'>rollouts</span><span class='p'>:</span>
    <span class='n'>C</span><span class='o'>.</span><span class='n'>ROLLOUTS</span> <span
            class='o'>=</span> <span class='n'>rollouts</span>

  <span class='n'>train_agent</span><span class='p'>(</span><span class='n'>PPOAgent</span><span
            class='p'>,</span>
              <span class='n'>C</span><span class='p'>,</span>
              <span class='n'>training_procedure</span><span class='o'>=</span><span
            class='n'>parallelised_training</span><span
            class='p'>(</span><span class='n'>training_procedure</span><span class='o'>=</span><span class='n'>batched_training</span><span
            class='p'>,</span>
                                                       <span
                                                               class='n'>auto_reset_on_terminal_state</span><span
            class='o'>=</span><span class='kc'>True</span><span class='p'>),</span>
              <span class='n'>parse_args</span><span class='o'>=</span><span class='kc'>False</span><span
            class='p'>,</span>
              <span class='n'>skip_confirmation</span><span class='o'>=</span><span class='n'>skip</span><span
            class='p'>)</span></div>


<span class='k'>if</span> <span class='vm'>__name__</span> <span class='o'>==</span> <span
                        class='s1'>&#39;__main__&#39;</span><span
                        class='p'>:</span>
  <span class='n'>ppo_test</span><span class='p'>()</span>
<span class='c1'># endregion</span>
</pre>
                </div>

            </div>

        </div>
    </div>
    <div aria-label='main navigation' class='sphinxsidebar' role='navigation'>
        <div class='sphinxsidebarwrapper'>
            <h1 class='logo'><a href='../../../index.html'>Agent</a></h1>


            <h3>Navigation</h3>
            <p class='caption'><span class='caption-text'>Notes</span></p>
            <ul>
                <li class='toctree-l1'><a class='reference internal'
                                          href='../../../../../../../apppath/docs/github/html/getting_started.html'>Getting
                    Started</a>
                </li>
                <li class='toctree-l1'><a class='reference internal'
                                          href='../../../../../../../notus/docs/github/html/concepts.html'>Core
                    Concepts</a>
                </li>
                <li class='toctree-l1'><a class='reference internal'
                                          href='../../../../../../../notus/docs/github/html/cli.html'>CLI
                    Reference</a>
                </li>
                <li class='toctree-l1'><a class='reference internal'
                                          href='../../../../../../../notus/docs/github/html/experiments.html'>Experiments</a>
                </li>
                <li class='toctree-l1'><a class='reference internal'
                                          href='../../../../../../../notus/docs/github/html/readme.html'>Readme
                    File</a>
                </li>
            </ul>
            <p class='caption'><span class='caption-text'>API</span></p>
            <ul>
                <li class='toctree-l1'><a class='reference internal'
                                          href='../../../../../../../notus/docs/github/html/api/agent.html'>agent
                    package</a>
                </li>
                <li class='toctree-l1'><a class='reference internal' href='../../../api/agent.agents.html'>agent.agents
                    package</a>
                </li>
                <li class='toctree-l1'><a class='reference internal'
                                          href='../../../../../../../apppath/docs/github/html/api/agent.utilities.html'>agents.utilities
                    package</a>
                </li>
                <li class='toctree-l1'><a class='reference internal'
                                          href='../../../../../../../apppath/docs/github/html/api/modules.html'>Agent</a>
                </li>
            </ul>

            <div class='relations'>
                <h3>Related Topics</h3>
                <ul>
                    <li><a href='../../../index.html'>Documentation overview</a>
                        <ul>
                            <li><a href='../../../../../../../apppath/docs/github/html/_modules/index.html'>Module
                                code</a>
                                <ul>
                                </ul>
                            </li>
                        </ul>
                    </li>
                </ul>
            </div>
            <div id='searchbox' role='search' style='display: none'>
                <h3 id='searchlabel'>Quick search</h3>
                <div class='searchformwrapper'>
                    <form action='../../../../../../../apppath/docs/github/html/search.html' class='search'
                          method='get'>
                        <input aria-labelledby='searchlabel' name='q' type='text'/>
                        <input type='submit' value='Go'/>
                    </form>
                </div>
            </div>
            <script type='text/javascript'>$('#searchbox').show(0);</script>


        </div>
    </div>
    <div class='clearer'></div>
</div>
<div class='footer'>
    &copy;2017, Christian Heider Nielsen.

    |
    Powered by <a href='http://sphinx-doc.org/'>Sphinx 2.1.0</a>
    &amp; <a href='https://github.com/bitprophet/alabaster'>Alabaster 0.7.12</a>

</div>


</body>
</html>
